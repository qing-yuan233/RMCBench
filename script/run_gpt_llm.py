import os
import requests
import time
import random
import pandas as pd
import io
import json
import argparse

# è°ƒç”¨æ¨¡å‹è·å¾—å›ç­”
def get_response(user_prompt, api_key, model_name):
    headers = {
        "Authorization": f"Bearer {api_key}"
    }
    data = {
        # "model":"gpt-4",
        "model": model_name,
        "messages": [
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": user_prompt}
        ]
    }

    try:
        response = requests.post("https://api.openai.com/v1/chat/completions", json=data, headers=headers)
        response_json = response.json()
        return response_json['choices'][0]['message']['content'] if response_json['choices'] else "æ— æ³•è·å–åˆ†æç»“æœ"
    except Exception as e:
        print(f"OpenAI API è¯·æ±‚å‡ºé”™: {e}")
        return False
    
# è¿”å›ä¸€ä¸ªdataframe
def read_prompt_from_xlxs_file(file_path):
    prompt_df = pd.read_excel(file_path,dtype=str)
    prompt_df['response'] = '' # å¢åŠ ä¸€åˆ—ä¿å­˜gptå›å¤
    return prompt_df

# å°†dfä¿å­˜ä¸ºæ–‡ä»¶
def save_res_file(prompt_df,output_file_dir,file_name,model_name):

    timestamp = time.strftime("%Y%m%d%H%M%S")

    if file_name == "tmp":
        timestamp = ""
    
    output_file = output_file_dir + f"res_{ model_name }_{timestamp}_{file_name}.xlsx"
    prompt_df.to_excel(output_file, index=False)
    print("ç»“æœæ–‡ä»¶å·²ä¿å­˜è‡³ï¼š",output_file)

# ä¸»å‡½æ•°
def main():
    """ ä¸»å‡½æ•° """
    # logo
    print("""
â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—  â–ˆâ–ˆâ•—
â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â• â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘
â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘
â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘
â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘
â•šâ•â•     â•šâ•â• â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â• â•šâ•â•  â•šâ•â•â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•â• â•šâ•â•â•â•â•â•â•šâ•â•  â•šâ•â•                                                               
          """)
    
    parser = argparse.ArgumentParser(description='é€šè¿‡å‚æ•°æŒ‡å®šæµ‹è¯•çš„æ¨¡å‹ã€ä»¥åŠå®éªŒè½®æ•°')
    parser.add_argument('--run_model_index',type=int,required=True, help='è¿è¡Œæ¨¡å‹çš„ç´¢å¼•')
    parser.add_argument('--run_rounds', type=int,nargs='+',required=True, help='æœ¬æ¬¡å®éªŒæ˜¯ç¬¬å‡ è½®(å¯ä»¥æ˜¯å¤šè½®)ï¼Œæ•°å­—ä»¥ç©ºæ ¼åˆ†å‰²')

    args = parser.parse_args()
    
    run_model_index = args.run_model_index
    run_rounds = args.run_rounds
    run_model_index = 0
    run_rounds = [2,3,4,5]


    model_info_dict = [
    {
        "mid":0,
        "dir_name":"gpt-3.5-turbo",
        "LLM_name":"ChatGPT"
    },
    {
        "mid":1,
        "dir_name":"gpt-4",
        "LLM_name":"ChatGPT"
    }]


    print("ä¸€å…±éœ€è¦è¿›è¡Œçš„è½®æ•°ï¼š",run_rounds)

    for run_round in run_rounds:
        print(f"ç¬¬{run_round}è½®å®éªŒ")

        prompt_file_path = f'D:\æ¡Œé¢\BaiduSyncdisk\RMCBench\data\prompt_v2\prompt_round_{run_round}.xlsx'
        model_info = model_info_dict[run_model_index]
        model_name = model_info["dir_name"]
        api_key = "your_api_key"  # open ai api key
        output_file_dir = 'D:/æ¡Œé¢/BaiduSyncdisk/RMCBench/res/'+model_name+f'/round{ run_round }/' # è¾“å‡ºæ–‡ä»¶è·¯å¾„,éœ€è¦åŒ…å«æœ€åçš„/

        print("******************************æœ¬æ¬¡è¿è¡Œå…³é”®å‚æ•°:******************************")
        print("model_name:",model_name)
        print("output_file_dir:",output_file_dir)
        # print("LLM_name:",model_name)
        print("****************************************************************************")

        # æ£€æŸ¥è¾“å‡ºè·¯å¾„
        if os.path.exists(output_file_dir):
            print(f"è¾“å‡ºç›®å½• {output_file_dir} å­˜åœ¨ã€‚")
        else:
            print(f"è¾“å‡ºç›®å½• {output_file_dir} ä¸å­˜åœ¨,è¿›è¡Œåˆ›å»º")
            os.makedirs(output_file_dir)
            print("åˆ›å»ºå®Œæˆï¼")

        print("ğŸ¤©ğŸ¤©ğŸ¤©ğŸ¤©ğŸ¤© "+model_name+",å¯åŠ¨ï¼ï¼ï¼ğŸ¤©ğŸ¤©ğŸ¤©ğŸ¤©ğŸ¤©")
                
        # å¼€å§‹æ—¶é—´
        start_time = time.perf_counter()
        
        prompt_df = read_prompt_from_xlxs_file(prompt_file_path)

        # ******************debug æŠ½æ ·æµ‹è¯•***********************************************************************************************
        # prompt_df = prompt_df.sample(n=5)
        # # é‡ç½®ç´¢å¼•ï¼Œæ–°çš„dataframeç´¢å¼•ä¹Ÿæ˜¯ä»0å¼€å§‹
        # prompt_df = prompt_df.reset_index(drop=True)
        # ******************************************************************************************************************************

        # è®¡ç®—æ ·æœ¬æ•°
        num_rows = len(prompt_df)
        print("total case: ",num_rows)

        # å¤„ç†æ¯ä¸€æ¡æ•°æ®ï¼Œè·å–å›ç­”
        index = 0
        same_error_times=0 # åˆå§‹åŒ–åŒä¸€æ¡æ ·æœ¬å‡ºç°é”™è¯¯çš„æœ€å¤§æ¬¡æ•°
        request_fail_index_set = set() # å‡ºé”™çš„æ ·æœ¬çš„id
        
        while index < num_rows:
            print("\n==========================================")
            print("now is procesiong index :" + str(index))
            row = prompt_df.iloc[index]
            print("pid is:"+ row["pid"])

            user_prompt = row['prompt']
            user_prompt = r''.join(user_prompt)
            print("\nprompt:")
            print(user_prompt)

            response = get_response(user_prompt,api_key,model_name) # è·å–å›ç­”
        
            print("\nLLM:")
            print(response)
            print("\n====================================================================================\n")

            prompt_df.at[index, 'response'] = response # å­˜å…¥dataframe
            index+=1
        
        # =====================================================================
        print("++++++++++++++++++++++++++++++++++å·²éå†å®Œè½®++++++++++++++++++++++++++++++++++")
        print("å¤±è´¥æ•°æ®çš„indexï¼š",request_fail_index_set)
        print("å…±",len(request_fail_index_set))
        # print("å…ˆä¿å­˜æ–‡ä»¶å¤‡ä»½ï¼Œä¹‹åç»§ç»­å¤„ç†æœªæˆåŠŸçš„æ•°æ®ç›´åˆ°å…¨éƒ¨æˆåŠŸ")
        print("+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++")

        save_res_file(prompt_df,output_file_dir,f"round{run_round}_first_try",model_name)

        # è®¡ç®—è€—æ—¶
        end_time = time.perf_counter()
        e2e_inference_time = (end_time-start_time)
        print(f"The time consuming is {e2e_inference_time} s")

        # ç»“æŸçš„å…·ä½“æ—¶é—´
        timestamp = time.strftime("%Y%m%d%H%M%S")
        # æœ¬æ¬¡è¿è¡Œçš„æ‰€æœ‰ä¿¡æ¯
        run_info = {
            "model_name":model_name,
            "end_time":timestamp,
            "time consuming":f"{e2e_inference_time} s",
            "error_id_list":list(request_fail_index_set)
        }

        # ä¿¡æ¯ä¿å­˜åˆ°æ–‡ä»¶
        with open(output_file_dir + f"run_info_{model_name}_{timestamp}_round{run_round}_done.json", 'w') as f:
            json.dump(run_info, f)

        print(f"round{run_round}è¿è¡Œå®Œæˆï¼Œè¾“å‡ºæ–‡ä»¶å·²ä¿å­˜åˆ°ç›®å½•ï¼š", output_file_dir)
    
    print("æ‰€æœ‰è½®æ¬¡å®éªŒå·²æ‰§è¡Œå®Œæ¯•ï¼")


if __name__ == "__main__":
    main()
